Gekaufte Kommentare
Betrug mit Views und Likes: Eine Studie zeigt, wie hilflos große Plattformen agieren
München – Die gute Nachricht: Große Plattformen erkennen Manipulationsversuche in sozialen Netzwerken besser als vor einem Jahr. Die schlechte Nachricht: Das ist noch viel zu wenig. Auch im Jahr 2020 braucht es nur wenige Euro und kaum technischen Sachverstand, um die Währung des Netzes zu fälschen: Auf Facebook, Instagram, Twitter, Youtube und Tiktok lassen sich massenhaft Likes und Kommentare kaufen. Das ist die zentrale Erkenntnis eines Experiments des Strategic Communication Centre of Excellence (Stratcom) der Nato. Die Denkfabrik beschäftigt sich oft mit russischen Desinformationskampagnen und gilt manchen als voreingenommen. Für den Bericht „Social Media Manipulation 2020“ spielt der politische Ost-West-Glaubenskrieg aber keine Rolle: Aufbau und Methodik der Untersuchung sind seriös.
  Eine Forscherin und drei Forscher haben für den Bericht überprüft, wie konsequent fünf Plattformen gegen Manipulation vorgehen. Sie kauften bei drei Dienstleistern Interaktionen für 39 Beiträge auf Facebook, Instagram, Twitter, Youtube und Tiktok. Für 300 Dollar erhielten sie rund 1100 Kommentare, knapp 10 000 Likes und mehr als 320 000 Views. Die gefälschten Interaktionen stammten von rund 8000 Accounts, die teils automatisiert erstellt und gesteuert, teils von Menschen angelegt und bedient werden.
  Dafür greifen die Dienstleister auf sogenannte Clickworker zurück, die für Centbeträge die monotone Arbeit ausführen. Das erschwert es den Plattformen, die Manipulation zu erkennen. Schließlich sind es Menschen und keine Bots, die da liken und kommentieren – nur steckt hinter den Interaktionen kein echtes Interesse für den Inhalt, sondern ausschließlich finanzielle Motivation. Eine Recherche von SZ, NDR und WDR zeigte vergangenes Jahr, dass auch deutsche Klickarbeiter Millionen gefälschte Interaktionen verteilen.
  Die Stratcom-Wissenschaftlerinnen und Wissenschaftler arbeiteten für ihre Untersuchung auch mit zwei Politikern zusammen, den US-Senatoren Chuck Grassley von den Republikanern und Chris Murphy von den Demokraten. Sie kauften kurz vor der US-Wahl gefälschte Interaktionen für Beiträge der beiden Politiker. Damit wollten sie herausfinden, ob die Plattformen verifizierte Accounts besonders schützen – und ob die Unternehmen im Vorfeld des wichtigsten politischen Ereignisses des Jahres besonders aufmerksam sind. Um auszuschließen, dass das Experiment versehentlich Einfluss auf den Wahlausgang nimmt, wählten die Forscher ältere, unpolitische Postings auf Facebook, Instagram und Twitter. Dafür kauften sie jeweils 1000 Likes und 50 Kommentare beziehungsweise Retweets und Antworten.
  Manchmal dauerte es Stunden oder Tage, bis die gekauften Interaktionen geliefert wurden. Auf Facebook tauchten nur knapp die Hälfte der versprochenen Kommentare auf, Twitter blockierte einen Teil der bestellten Likes. Dennoch ließen sich alle drei Plattformen von den Dienstleistern manipulieren. Nach einer Woche meldeten die Forscher einen Teil der Manipulationen, selbst danach blieb ein Großteil online. Das Fazit des Berichts ist eindeutig: „Es braucht deutlich größere Anstrengungen, um offizielle Accounts zu schützen, Bot-Netzwerke zu erkennen und kommerzielle Manipulation zu verhindern, um den Online-Diskurs zu schützen.“
  Das gilt nicht nur für Beiträge von Senatoren, sondern für alle Nutzerinnen und Nutzer auf großen Plattformen. Im Vergleich zu einer ähnlichen Studie vor einem Jahr fällt es Facebook-Betrügern nun schwerer, gefälschte Konten anzulegen. Twitter ist ein bisschen besser darin geworden, diese Accounts nachträglich zu sperren und automatisierte Manipulationsversuche zu erkennen. Bei Instagram und Youtube hat sich kaum etwas getan, Interaktionen auf beiden Plattformen lassen sich mit Leichtigkeit fälschen. „Instagrams Mutterkonzern Facebook sollte seine Expertise weitergeben“, raten die Forscher.
  Das hätte auch Tiktok nötig. Die Plattform scheine nicht in der Lage zu sein, selbst die billigsten Manipulationsversuche zu entfernen und seine Nutzer zu schützen, heißt es in dem Bericht. Während des mehrwöchigen Experiments sperrte Tiktok keinen einzigen Fake-Account und löschte nicht eine gefälschte Interaktion. Das Einzige, was die Wissenschaftler Tiktok zugutehalten: „Es lässt die Bemühungen der anderen Plattformen in einem deutlich besseren Licht dastehen.“
  Zumindest in einer Hinsicht gibt der Stratcom-Bericht Entwarnung. Es mag immer noch möglich sein, für eine Handvoll Dollar die Metriken sozialer Medien zu manipulieren. Der politische und gesellschaftliche Schaden hält sich in Grenzen. Die dubiosen Dienstleistungen werden vor allem von kleinen Unternehmen oder Kriminellen in Anspruch genommen, die glauben, damit ihren Umsatz steigern zu können.
  Bei wichtigen Wahlen oder Themen wie der Corona-Pandemie scheinen gefälschte Interaktionen nur eine geringe Rolle zu spielen. Für die Glaubwürdigkeit der Plattformen ist das eine gute Nachricht. Für den Glauben an die Menschheit eher nicht: Hinter Millionen Accounts, die Lügen über Covid-19 liken und Panik vor einem Impfstoff schüren, stecken keine Bots. Es sind echte Menschen.
SIMON HURTZ
Tiktok scheint nicht fähig zu sein,
billigste Manipulationsversuche
zu erkennen
Die Währung des Internets: Likes, Views, Follower.
Foto: Bloomberg
