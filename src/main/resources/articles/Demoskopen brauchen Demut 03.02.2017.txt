http://www.sueddeutsche.de/wissen/big-data-demoskopen-brauchen-demut-1.3362769
Big Data
Demoskopen brauchen Demut
Je mehr Daten, umso besser die Prognose, hieß es lange. Seit den falschen Vorhersagen beim Brexit und der US-Wahl stehen Wahlforscher in der Kritik. Welche Macht hat Big Data wirklich?
Von Christoph Behrens
Lange hieß es: Je mehr Daten es gibt, umso genauer lassen sich Vorhersagen über politische Entscheidungen treffen. Dann stimmte Großbritannien für den Brexit und die USA wählte Donald Trump zum Präsidenten. In beiden Fällen lagen Wahlforscher trotz ausgefeiltester mathematischer Modelle, gespeist von Tera-, Peta- und Exabytes an Daten, grob daneben .
Eine Reihe Artikel im Wissenschaftsmagazin Science versucht nun zu klären, was Big Data und Vorhersage-Techniken heute angesichts politischer und wirtschaftlicher Krisen leisten können. Die Antwort: Es wird komplizierter gute Prognosen zu treffen. Aber es ist weiterhin möglich - und etwas mehr Demut vonseiten der Wissenschaftler wäre dabei hilfreich.
Menschen verhalten sich selten wie berechnet
Zunächst der positive Teil: Zwar lagen Demoskopen bei Brexit und der aktuellen US-Wahl größtenteils falsch, insgesamt schneiden sie aber nicht schlecht ab. Bei den US-Wahlen 2012 etwa sagte der Datenwissenschaftler Nate Silver die Ergebnisse aller 50 Bundesstaaten richtig voraus, auch andere Wahlforscher lagen sehr nahe am tatsächlichen Ergebnis. In Science berichtet ein Team um Ryan Kennedy von der Universität Houston nun von einem neuen mathematischen Modell, das 80 bis 90 Prozent aller Wahlen korrekt vorhersagen kann. Meist weiß ihr Programm im Vorfeld einer Wahl, ob der Amtsinhaber gewinnt oder der Herausforderer.
Bemerkenswert ist an dem Prognose-Werkzeug, dass es nicht auf ein Land beschränkt ist. Die Datenwissenschaftler verwendeten als Grundlage 621 Wahlergebnisse seit 1945 aus 86 verschiedenen Ländern, um zu einem globalen Wahl-Modell zu kommen. So unterschiedliche Faktoren wie der Grad der Demokratisierung, die Stärke der Wirtschaft oder die Außenpolitik eines Landes fließen darin ein - aber auch die Ergebnisse von Wählerbefragungen vor Ort. Anhand dieser 21 Faktoren sagten die Forscher zehn von elf Wahlen in Südamerika zwsichen 2013 und 2014 korrekt voraus, und 29 von 36 Wahlen in anderen Weltregionen.
Überraschenderweise hatte die wirtschaftliche Lage eines Landes kaum einen Einfluss, ob der Amtsinhaber gewinnt oder der Herausforderer. Ein stärkerer Indikator war beispielsweise, wie viele internationale Hilfsgelder ein Staat erhält - je mehr, umso bessere Chancen hatten neue Parteien. Der beste Faktor für die Pronose seien aber unabhängige Umfragen unter den Wählern, schreiben die US-Forscher. "Umfragen können nicht nur in den USA, sondern global dazu dienen, Wahlen vorherzusagen", sagt der Autor der Studie Ryan Kennedy. Es sei daher ein Fehler, auf solche Umfragen künftig zu verzichten - Kritik daran wurde beispielsweise nach der US-Wahl laut.
Doch warum gelang es in den USA trotzdem nicht, den Wählerwillen verlässlich abzufragen? Hier beginnt der aus wissenschaftlicher Sicht unangenehme Teil. Jake Hofman von der Forschungsabteilung von Microsoft zieht zur Erklärung zwei Extreme der Vorhersehbarkeit heran: regelmäßige Ereignisse und sogenannte "Schwarze Schwäne". Regelmäßige Ereignisse sind einfach vorherzusagen. Beispielsweise zeigte eine Studie von 50 000 Handynutzern, dass diese sich 70 Prozent der Zeit an ihrem bevorzugten Ort aufhalten, beispielsweise dem Arbeitsplatz oder Zuhause. Mit 70-prozentiger Genauigkeit lässt sich also recht einfach vorhersagen, wo sich jemand zu einem beliebigen Zeitpunkt befindet. "Schwarze Schwäne" dagegen werden Ereignisse wie die Finanzkrise von 2008 genannt. Sie sind sehr selten und völlig unmöglich vorherzusagen. Das Ergebnis einer US-Präsidentschaftswahl bewegt sich in ihrer Vorhersehbarkeit irgendwo dazwischen - eine richtige Prognose ist zwar nicht völlig unmöglich, aber auch nicht völlig sicher.
"Wenn Vorhersagen nicht perfekt sind, könnte das an einer zu geringen Datenmenge liegen", schreibt Hofman , "aber es könnte auch sein, dass das Phänomen selbst unvorhersehbar ist und die Genauigkeit der Vorhersage an eine fundamentale Grenze stößt". Das bedeutet, dass eine komplexe Welt sich niemals vollständig vermessen lässt, sondern immer ein Rest Unsicherheit bleibt. Der Erfolg Donald Trumps lässt sich nicht allein mit seinem Auftreten in den Medien, seinen politischen Fähigkeiten oder dem Zustand der USA erklären. Auch der Zufall spielt eine wichtige Rolle, und dies lasse sich nicht durch genauere Modelle wegrechnen , argumentiert Hofman. Je höher solche externen Zufallsfaktoren, umso niedriger ist die Chance einer richtigen Vorhersage.
Big Data allein ist der komplexen Welt nicht gewachsen
Das Problem für Wahlforscher ist derzeit, dass diese fundamentale Unsicherheit steigt. "Faktoren, die Prognosen früher Sicherheit gegeben haben, nehmen ab", sagt der Politikwissenschaftler Eric Linhart von der Technischen Universität Chemnitz. Beispielsweise sinke die Identifikation mit einer bestimmten Partei in vielen Ländern, auch in Deutschland. "Da ist insgesamt mehr Spiel drin", sagt Linhart. Wenn ein Wähler bis fünf Minuten vor der Stimmabgabe selbst nicht wisse, für wen er stimmen wird, "dann kann man das auch nicht prognostizieren". Wahlentscheidungen seien heute zunehmend "von augenblicklichen Stimmungen abhängig", sagt der Soziologe Sighard Neckel von der Uni Hamburg. Ereignisse wie ein Terroranschlag könnten die Emotionen schnell kippen lassen. Daher steige die Unsicherheit von Prognosen tendenziell. "Die Volatilität hat zugenommen", sagt Neckel. Laut Microsoft-Forscher Hofman müssen Demoskopen daher eine obere Grenze der Genauigkeit für Vorhersagen akzeptieren - und mit der Unsicherheit leben lernen.
Diese neue Demut ist eine kleine Überraschung im Zeitalter der großen Datenmengen. Schließlich galt es bisher als ausgemacht, dass eine größere Datenmenge allein zu besseren Ergebnissen führt. 2008 proklamierte der Chefredakteur der Zeitschrift Wired , Chris Anderson, gar das "Ende der Theorie" . In der Ära der Petabytes brauche es keine Modelle oder Hypothesen mehr, "mit genug Daten sprechen die Zahlen für sich selbst". Nun bemerkt der Konfliktforscher Lars-Erik Cederman nüchtern, "die Hoffnung, dass Big Data irgendwie valide Vorhersagen ermöglicht", durch eine Art theorie-freie, rohe Gewalt der Zahlen, "ist fehl am Platz".
Big-Data-Prognosen sind trotz Kritik weiter auf dem Vormarsch
In der Konfliktforschung wird beispielsweise seit Jahren anhand großer Datenmengen versucht vorherzusagen, wo und wann in einer Region Gewalt aufflammt. Es gebe zwar vereinzelte Fortschritte bei diesem Unterfangen, ein verlässliches "Frühwarnsystem" für Gewalt sei aber nicht in Sicht. Als Grund führen die Forscher eine "massive historische Komplexität" und menschengemachte Eventualitäten an. Historische "Unfälle" wie der Brexit oder der Erfolg Donald Trumps verhöhnten noch die besten Modelle.
Allerdings ist diese Bescheidenheit noch nicht überall angekommen. Ganz im Gegenteil: Big-Data-Prognosen sind weiter auf dem Vormarsch. Mittlerweise entscheidet Vorhersage-Software in einigen US-Städten, in welche Viertel Polizisten oder Brandschutz-Inspektoren geschickt werden, weil der Algorithmus an dem betreffenden Ort einen möglichen Gefahrenherd wittert. In der Medizin setzen einzelne Tools Patienten auf der Warteschlange für dringend benötigte Operationen nach oben - weil bei ihnen laut Algorithmus weniger Komplikationen zu erwarten sind. Heikle Fragen liegen bei solchen Anwendungen auf der Hand. So könnte ein Hausbesitzer oder Restaurantbetreiber Sicherheitsvorkehrungen absenken, sobald er herausgefunden hat, dass sein Risiko von einem Brandschutzinspektor kontrolliert zu werden gering ist.
Ein tiefergehendes Problem hat mit einem mangelnden Verständnis der Big-Data-Modelle zu tun. Die Softwares basieren häufig auf dem Prinzip des überwachten maschinellen Lernens. Ein Algorithmus wird mit einer großen Menge "Trainingsdaten" gefüttert - aus diesen gewinnt er Regeln für den Datensatz. Ein fiktives Beispiel: Wenn das Wirtschaftswachstum gering ist, hat eine linke Partei bessere Chancen auf einen Wahlsieg, könnte ein solches Programm aus historischen Wahldaten ableiten. Die besten derartigen Modelle sind aber weitaus komplexer, so komplex, dass die Regeln die sie aufstellen, für ihre menschlichen Entwickler teilweise gar nicht mehr nachvollziehbar sind. Beispielsweise könnte der Computer zu dem Schluss kommen, dass es auch etwas mit dem Wetter oder dem Aktienkurs von Toyota zu tun hat, ob ein linker Politiker gewinnt. Möglicherweise ist das reiner Zufall, möglicherweise führen diese Faktoren tatsächlich im Durchschnitt zu besseren Prognosen. Nur lassen diese sich dann nicht mehr vernünftig erklären.
SZ.de
